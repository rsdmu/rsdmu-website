---
title: "The Right to AI: A Participatory Framework for AI as Societal Infrastructure"
date: "2025-08-09"
path: "right-to-ai"
type: "work"
thumbnail: "./images/right-to-ai-cover.png"
author: "Rashid Mushkani"
description: "A declaration, research agenda, and nonprofit initiative enabling communities to co‑design, oversee, and steward AI that shapes daily life."
---

## Problem

AI systems increasingly shape everyday life—public space, finance, healthcare, education—yet most people have little say in how these systems are designed, deployed, and governed. Current models concentrate power in a few institutions and treat the public as consumers rather than co‑creators, risking bias, exclusion, and a loss of democratic legitimacy.

## Overview

Since 2022, **The Right to AI** has grown from a three‑year multidisciplinary collaboration with **30+ community organizations across Montréal** into a non‑profit organization. Our aim is to make AI a **societal infrastructure** governed with **pluralism, transparency, and shared stewardship**—not just *AI for* the people, but **AI by the people**.

## What We Do

<div style="margin-left: 40px;">

- **Workshops.** Community co‑creation sessions where participants prototype with and critically reflect on AI systems—surfacing benefits, harms, and local priorities.  
- **Research.** Peer‑reviewed studies and open data on methods for public participation across the AI lifecycle (data, design, deployment, oversight).  
- **Advocacy.** Policy engagement to elevate the voices most affected by automated systems yet least consulted in their creation.

</div>

## The Right to AI (paper)

<div style="margin-left: 40px;">

This paper argues that people and communities have a **Right to AI**—a governance right to shape, critique, and oversee AI infrastructures. Extending Lefebvre’s *Right to the City* and drawing on Arnstein’s ladder, the paper:
  
- Reframes **AI as societal infrastructure** requiring collective governance.  
- Analyzes challenges posed by generative agents, large‑scale data extraction, and value pluralism.  
- Proposes **grassroots participatory methodologies**, shared data stewardship, and transparent design processes.  
- Distills lessons from **nine participatory AI case studies** and introduces a **four‑tier model** for participation.

</div>

## Four‑Tier Ladder of the Right to AI

<div style="margin-left: 40px;">

1. **Consumer‑Based (Minimal Right).** People use AI with little influence beyond surveys/feedback; power remains centralized.  
2. **Private Organization‑Led.** Companies integrate limited stakeholder input; transparency improves but conflicts of interest persist.  
3. **Government‑Controlled.** Regulation and consultations add accountability, but may miss local contexts and lived expertise.  
4. **Citizen‑Controlled (Maximal Right).** Community assemblies, data trusts, and co‑ownership of datasets enable **shared authority** over objectives, risks, and audits—with expert collaboration where stakes are high.

</div>

## Lessons from Practice

<div style="margin-left: 40px;">

- **Engage early & continuously.** Early involvement prevents tokenism and surfaces value conflicts before they harden.  
- **Balance expertise and lived experience.** Translational facilitation and community‑guided metrics bridge technical and local knowledge.  
- **Resource for equity.** Durable participation needs training, open tools, and institutional support to avoid participation‑washing.  
- **Make participation consequential.** Tie deliberation to clear changes in data policy, model objectives, and deployment decisions.

</div>

## Recommendations

<div style="margin-left: 40px;">

- **Build capacity:** AI literacy programs, open educational materials, and accessible tooling.  
- **Facilitate participation:** Interfaces for feedback, translation, and co‑creation—powered by LLMs where helpful.  
- **Formalize assemblies:** Local AI councils that can mature from advisory roles to decision authority.  
- **Establish data trusts & audits:** Community‑governed data stewardship and transparent, public‑facing audits.  
- **Localize models:** Fine‑tune with community‑curated datasets for context‑sensitive behavior.  
- **Mediate conflicts:** Standing panels for ethical disputes and cultural sensitivities.  
- **Mobilize researchers:** Incentives and practices that embed community engagement throughout the AI lifecycle.

</div>

## How You Can Help

<div style="margin-left: 40px;">

- **Volunteer** to share and activate the Right to AI in your community or field.  
- **Join research projects** on public participation in AI.  
- **Collaborate** on a study, workshop, or pilot deployment.  
- **Contact:** <contact@therighttoai.org>

</div>

## Outputs & Materials

<div style="margin-left: 40px;">

- [The Right to AI (non-profit)](https://www.therighttoai.org/)  
- [About The Right to AI](https://www.therighttoai.org/about)  
- [Book on the Right to AI](https://www.therighttoai.org/book)  

</div>


## Visual

<div align="center">

![Poster/visual summary for The Right to AI](./images/right-to-ai-poster.png)

</div>

## How to Cite

Mushkani, R., Berard, H., Cohen, A., & Koseki, S. (2025). **Position: The Right to AI.** *Proceedings of the 42nd International Conference on Machine Learning (ICML 2025), PMLR 267, Vancouver.* arXiv:2501.17899.



## Tags

<div class="tags">
  <span class="tag">AI Governance</span>
  <span class="tag">Participation</span>
  <span class="tag">Pluralism</span>
  <span class="tag">Open Source</span>
  <span class="tag">Data Stewardship</span>
  <span class="tag">Workshops</span>
  <span class="tag">Montréal</span>
</div>
