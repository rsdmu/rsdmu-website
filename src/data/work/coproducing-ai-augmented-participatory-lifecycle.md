---
title: "Build AI With People, Not For Them: The 5-Phase Co-Production Playbook"
date: "2025-07-31"
path: "coproducing-ai-augmented-participatory-lifecycle"
type: "work"
thumbnail: "./images/design.png"
author: "Rashid Mushkani"
description: "A no-nonsense, five-phase guide to building AI *with* communities—so decisions, risks, and benefits are shared from day one."
---

*Five steps to build AI that communities actually trust—and help shape.*

[Read the Paper on arXiv](https://arxiv.org/abs/2508.00138)

[![Read the Paper on arXiv](./images/design.png)](https://arxiv.org/abs/2508.00138)


## Why This Matters

Most AI is still built *about* people, not *with* them.  
**Co-Producing AI** flips the script—making communities equal partners in every step, from defining the problem to deciding when to shut a system down.  

No token feedback. No “we’ll circle back later.”  
Just shared power, transparent choices, and ongoing accountability.


## The 5 Phases of People-First AI

1. **Co-Framing** → Work out the problem *together*. Who’s affected? What are the risks? Who gets a say (and a veto)?
2. **Co-Design** → Choose data, models, and interfaces via participatory prototyping. Weigh accuracy, privacy, explainability, and cost *in the open*.
3. **Co-Implementation** → Train or fine-tune with full transparency. Publish model cards, data summaries, and error logs for public review.
4. **Co-Deployment** → Roll out with clear recourse channels, anti–scope creep rules, and rollback triggers.
5. **Co-Maintenance** → Keep auditing—not just for tech drift, but for ethical and participatory health. Re-consent when features change.


## Workshop Insights

- **Share the power** → Move real decision rights to those most impacted.  
- **Keep learning loops alive** → Feedback isn’t a one-off—it’s a habit.  
- **Match privacy to context** → One-size-fits-all doesn’t fit privacy.  
- **Fund participation** → Pay for travel, childcare, accessibility—so everyone can show up.


## What You Walk Away With

- A **governance charter** with real decision rights (and appeal points).  
- A **public model card & data sheet** tied to community decisions.  
- A **recourse & transparency portal** (dashboards, release notes, audit logs).  
- An **audit schedule** that covers tech, ethics, and participation.


## How We Built It

- **4 multidisciplinary workshops** (Montréal, 2024) with 20 experts from research, industry, and civil society.  
- **Scoping review** of 76 key works across computer science, social science, humanities, and policy (2013–2024).


## Why It’s Different

Global AI frameworks (like the Montréal Declaration, IEEE EAD, NIST AI RMF, EU Trustworthy AI) give us the *principles*.  
This adds the missing **“how”**—with concrete checkpoints, ongoing co-maintenance, and clear governance.


## Visuals

![Lifecycle overview.](./images/coproducing_ai_lifecycle.png)  
*Five phases connected by continuous feedback and shared accountability.*

![Risks in Design versus Co-design.](./images/design.png)  
*Design vs. Co-design.*

## Where This Works Best

- **AI Governance:** Turn big principles into everyday routines.  
- **High-Stakes AI:** Health, finance, public services—anywhere trust is essential.  
- **Org Culture:** Replace “participation-washing” with real, funded involvement.


**Links:**  
- Paper → [arXiv:2508.00138](https://arxiv.org/abs/2508.00138)  
- UNESCO Chair in Urban Landscape → <https://unesco-studio.umontreal.ca/>  
- Mila – Quebec AI Institute → <https://mila.quebec/>

**Tags:**  
AI Governance · Participatory AI · Co-design · Design Justice · Expansive Learning · DEI
